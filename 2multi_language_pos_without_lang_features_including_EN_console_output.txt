2019-07-17 07:41:54 - root - INFO - Starting do_mega_multilingual_model_all_features(dedirpath, "de", itdirpath, "it", czdirpath, "cz", endirpath, "en", "pos", False)
Doing: take all data as if it belongs to one large dataset, and do classification
Mega classification for:  pos  features
7467 7467 7467 942
Distribution of labels: 
Counter({'B1': 4666, 'A2': 1835, 'B2': 838, 'A1': 86, 'C1': 42})
Printing results for: RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)CountVectorizer(analyzer='word', binary=False, decode_error='strict',
                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
                lowercase=True, max_df=1.0, max_features=None, min_df=10,
                ngram_range=(1, 5), preprocessor=None, stop_words=None,
                strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
                tokenizer=None, vocabulary=None)
33075
33075
[0.50066756 0.53137517 0.89973262 0.79411765 0.76871658 0.62516734
 0.62013423 0.63489933 0.63306452 0.62634409]
0.6634219063759521 0.6345790895798544
C:\Users\jean-\Anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
[[  23   63    0    0    0    0]
 [  60  681 1090    4    0    0]
 [   1  465 4046  154    0    0]
 [   0   12  622  204    0    0]
 [   0    0    1   41    0    0]
 [   0    0    0    0    0    0]]
Printing results for: LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)CountVectorizer(analyzer='word', binary=False, decode_error='strict',
                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
                lowercase=True, max_df=1.0, max_features=None, min_df=10,
                ngram_range=(1, 5), preprocessor=None, stop_words=None,
                strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
                tokenizer=None, vocabulary=None)
33075
33075

[0.37249666 0.40186916 0.61898396 0.61764706 0.45454545 0.39223561
 0.49798658 0.57181208 0.5577957  0.5577957 ]
0.5043167956353691 0.5118859907571948
[[  19   63    4    0    0    0]
 [ 160  632  993   50    0    0]
 [  12 1255 2868  529    2    0]
 [   0   90  484  242   22    0]
 [   0    1    4   33    4    0]
 [   0    0    0    0    0    0]]
Printing results for: LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=1234, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False)CountVectorizer(analyzer='word', binary=False, decode_error='strict',
                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
                lowercase=True, max_df=1.0, max_features=None, min_df=10,
                ngram_range=(1, 5), preprocessor=None, stop_words=None,
                strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
                tokenizer=None, vocabulary=None)
33075
33075

[0.376502   0.39786382 0.64839572 0.63636364 0.45053476 0.38554217
 0.51275168 0.57583893 0.57392473 0.57795699]
0.5135674431873504 0.5198090927161054
[[  18   66    2    0    0    0]
 [ 173  626  995   41    0    0]
 [  16 1175 2943  531    1    0]
 [   0   70  497  243   28    0]
 [   0    1    3   34    4    0]
 [   0    0    0    0    0    0]]
SAME LANG EVAL DONE FOR THIS LANG
Doing: take all data as if it belongs to one large dataset, and do classification
2019-07-17 08:23:00 - root - INFO - Finished do_mega_multilingual_model_all_features(dedirpath, "de", itdirpath, "it", czdirpath, "cz", endirpath, "en", "pos", False)
